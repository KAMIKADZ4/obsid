## От процессора до многопоточки
Процессор - это тот самый физический камень на материнской плате, что вставляется в сокет.

Многопроцессорных системах (параллельны) процессоры находят физически и логически далеко друг от друга. В многоядерных системах св процессоре появились несколько идентичных друг к другу компонентов(ядер) позволяющие исполнять части параллельных программ.
В однопроцессорной многозадачной системе поддерживается так называемое псевдопараллельное исполнение.

В итоге процессор состоят из:
* Ядер
    * Регистры - хранят текущие команды и промежуточные результаты операций
    * Кеши L2 и L1
    * Арифметико-логическое устройство (АЛУ) - выполняет математические и логические операции
    * Управляющее устройство (УУ) - управляет работой процессора с помощью электрических сигналов
* Кеш L3 - память для хранения часто используемых команд и данных из  оперативки для быстроты обращения к ним
* Шины - физические каналы, по котором передается информация между процессором, оперативной памятью и другими устройствами 

Статья о внутреннем устройстве процессора https://skillbox.ru/media/code/chto-takoe-processor-i-kak-on-rabotaet/

В характеристиках процессора всегда помимо числа ядер указывается и число потоков(Kernel Thread). Производители усовершенствовали ядра, добавив доп контроллер и набор регистров для создания второго канала обработки данных. Технологии, позволяющие ядру работать с несколькими потоками, у разных производителей свои: Hyper-Threading у Intel и Simultaneous Multithreading (SMT) у AMD.
## Перейдем уже к ОС
Теперь разберемся, что такое процесс и поток(user thread)

**С точки зрения пользователя:**
Процесс - это выполняемый экземпляр программы.
Поток - ветки кода, выполняющиеся "параллельно", тоесть без предписанного порядка выполнения во времени

**С точки зрения ОС:**
Процесс - абстракция ОС для организации данных для работы программы. У процесса свое адресное пространство, потоки, открытые файлы, дочерние процессы и тд.
Поток - абстракция на уровне ОС, для контроля выполнения кода программы. У потока есть свой стек

Каждый поток, как и каждый процесс, имеет свой контекст. Контекст - это структура, в которой сохраняются следующие элементы: регистры процессора, указатель на стек потока/процесса.

Создание потока дешевле, чем создание нового процесса, тк для процесса требуется создание нового адресного пространства, в то время как поток использует адресное пространство процесса, что его создал. И также переключение между потоками происходит быстрее между процессами

По умолчанию процесс имеет один процесс имеет один поток. Приложение может иметь сотни потоков и при этом не потреблять много ресурсов ядра. 

https://habr.com/ru/sandbox/173396/

Планировщик пользовательских потоков ОС сам распределяют пользовательские потоки по потокам ядра

https://habr.com/ru/articles/40227/

https://habr.com/ru/companies/otus/articles/549814/

## Итог теории
Подведем небольшое теоретические итоги по процессам ядра и пользовательским потокам

| Потоки ядра                                                                                       | Пользовательские потоки                                                                |
| ------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| Управляются ОС                                                                                    | Управляются пользовательским пространством (создать поток и тп)                        |
| Имеют доступ ко всем ресурсам системы: памяти, устройствам ввода-вывода, аппаратным прерываниям.  | Имеют доступ только к ресурсам своего процесса и работают в его адресном пространстве. |
| Используются для выполнения системных задач (например, управление памятью, обработка прерываний). | Используются для выполнения задач программы, инициируемых пользователем.               |
| Планируются ядром с использованием системного планировщика.                                       | Планируются библиотекой в пользовательском пространстве (например, рантаймом языка).   |

Модели сопоставления пользовательских потоков с потоками ядра

| Модель             | Описание                                                                                                  |
| ------------------ | --------------------------------------------------------------------------------------------------------- |
| One-to-One (1:1)   | Каждый пользовательский поток напрямую связан с потоком ядра. Пример: POSIX Threads в Linux               |
| Many-to-One (M:1)  | Несколько пользовательских потоков сопоставляются с одним потоком ядра. Пример: Старая библиотека GNU Pth |
| Many-to-Many (M:N) | Пользовательские потоки отображаются на несколько потоков ядра. Пример: технология в Solaris.             |

Таблицы созданы с использованием GPT
Далее рассмотрим уже только пользовательские потоки, а потоки ядра это слишком низкий уровень для системных программистов
## Что там с многопоточкой на Python

## GIL (Global Interpreter Lock)

GIL - это глобальная блокировка интерпретатора, которая используется в CPython, для управления доступа к объектам данных, обеспечивая их потокобезопасность. GIL действует как мюьтекс, поэтому когда поток начинает выполняться он "захватывает" GIL, и пока он работают другое потоки ожидают освобождения блокировки. Поток, совершающий операцию I/O, может отпустить блокировку, позволяю другим потокам работать 

GIL позволяет только одному потоку Python выполнять байт-код в любой момент времени. Даже если будут запущены одновременно несколько потоков, в один момент времени будет выполняться только один (это гарантирует GIL), остальные потоки находятся в ожидании. 

Зачем GIL нужен в Python? GIL предотвращает конкурентный доступ потоков к памяти, что позволяет упростить работу сборщика мусора([[Python GC]]). 

https://habr.com/ru/articles/84629/ (2010 год)

### Threading
Посмотрим работу threading
```python
import threading as th
import time


counter = 0

def func(name):
    global counter
    start_t = time.time()
    for i in range(5_000_000):
        counter += 1
    print('time', name, (start_t, time.time()))


start_time = time.time()
t1 = th.Thread(target=func, args=('a', ))
t2 = th.Thread(target=func, args=('b', ))
t1.start()
t2.start()

t1.join()
print('t1 join end')
t2.join()
print('t2 join end')

print('bye', c, 
	  time.time() - start_time)
# time b (1737327972.7105765, 1737327982.8204405)
# time a (1737327972.7051187, 1737327982.830712)
# t1 join end
# t2 join end
# bye 10000000 10.126368522644043
```

В этом коде по выводу можно понять, что потоки выполнялись по очереди,переключаясь в процессе(видно по рамкам времени работы t1 и t2 потока) и GIL не допустил одновременной работы потоков. В данном коде не хватает блокировки для доступа к переменной `counter`, тк GIL нацелен на защиту внутренних структур данных Python. Без блокировки переключение потока может произойти в неподходящий момент.

```python
import time


counter = 0

def func(name):
    global counter
    start_t = time.time()
    for i in range(5_000_000):
        counter += 1
    print('time', name, (start_t, time.time()))

start_time = time.time()
func('a')
print('1st func end')
func('b')
print('2nd func end')

print('bye', c, 
	  time.time() - start_time)
# time a (1737328383.4519653, 1737328384.1095204)
# 1st func end
# time b (1737328384.1096752, 1737328384.762561)
# 2nd func end
# bye 10000000 1.3106598
```

Во втором примере потоков других нет, функции выполнялись последовательно и крайне быстро 

```python
# ПОТЕСТИТЬ КОД тк не получается data raise 
from threading import *

def work(i):
    for _ in range(100):
        print(f"hello i'm a thread #{i}")

t1 = Thread(target=work, args=(1,))
t2 = Thread(target=work, args=(2,))
t1.start()
t2.start()
t1.join()
t2.join()
```

### Concurrent.futures
модуль для предоставления высокоуровневый интерфейса для ассинхронного выполнения вызываемых объектов.

`ThreadPoolExecutor` - обеспечивает ассинхронное выполнение с помощью потоков, или с помощью процессов за счет `ProcessPoolExecuter`.

#### ThreadPoolExecutor
```python
from concurrent.futures import ThreadPoolExecutor

def task_function(param):    
	# Реализация задачи    
	return result
# Создание ThreadPoolExecutor с 4 рабочими потоками
with ThreadPoolExecutor(max_workers=4) as executor:    
	# Запуск задачи асинхронно
    future = executor.submit(task_function, param)
    # Ожидание результата и получение его
    result = future.result()
```

#### ThreadPoolExecutor
```python
from concurrent.futures import ProcessPoolExecutor

def task_function(param):    
	# Реализация задачи    
	return result
# Создание ProcessPoolExecutor с 4 рабочими процессами
with ProcessPoolExecutor(max_workers=4) as executor:    
	# Запуск задачи асинхронно
    future = executor.submit(task_function, param)
    # Ожидание результата и получение его
    result = future.result()
```


Объекты Future позволяют собой асинхронные задачи, которые были отправлены на выполнение. Можно достаточно легко отслеживать статус и получать результаты задачи `future.result()`. Так же можно и ошибки обработать, возникшие при выполнении:
```python
try:    
	result = future.result()
except Exception as e:
	print(f"Произошла ошибка: {e}")
```

concurrent.futures самостоятельно управляет пулом потоков/процессов и распределяет задачи между ними, что делает это библиотеку отличным инструментом.
https://habr.com/ru/companies/otus/articles/771346/
### Объединение asyncio и многопоточности
[[Python асинхронность]] - подробнее про асинхронность в python

```python
import asyncio
import concurrent.futures

def blocking_io():
    # File operations (such as logging) can block the
    # event loop: run them in a thread pool.
    with open('/dev/urandom', 'rb') as f:
        return f.read(100)

def cpu_bound():
    # CPU-bound operations will block the event loop:
    # in general it is preferable to run them in a
    # process pool.
    return sum(i * i for i in range(10 ** 7))

async def main():
    loop = asyncio.get_running_loop()

    ## Options:

    # 1. Run in the default loop's executor:
    result = await loop.run_in_executor(
        None, blocking_io)
    print('default thread pool', result)

    # 2. Run in a custom thread pool:
    with concurrent.futures.ThreadPoolExecutor() as pool:
        result = await loop.run_in_executor(
            pool, blocking_io)
        print('custom thread pool', result)

    # 3. Run in a custom process pool:
    with concurrent.futures.ProcessPoolExecutor() as pool:
        result = await loop.run_in_executor(
            pool, cpu_bound)
        print('custom process pool', result)

if __name__ == '__main__':
    asyncio.run(main())
```
https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.run_in_executor

В документации описана интеграция синхронного блокирующего кода в асинхронный код

В примерах описано как можно выполнять синхронные таски в отдельном потоке (1 и 2 примеры)
В примере 3 уже выполняется в отдельном процессе, тк задача не имеет блокировок I/O
